# This compose file defines a complete local LLM environment based on the
# configuration provided by the user. In addition to Ollama and
# Open‑WebUI, it adds a lightweight Python service that exposes a simple
# REST API for controlling Proxmox. The controller service uses the
# `proxmoxer` library to interact with the Proxmox API and reads its
# connection settings from environment variables. Adjust the values in
# a `.env` file or export them in your shell before running
# `docker‑compose up -d`.
services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    environment:
      # Prevent the model from spinning endlessly after a response
      - OLLAMA_KEEP_ALIVE=30s
      - OLLAMA_NUM_THREADS=4
      - OLLAMA_NUM_PARALLEL=1
      - OMP_NUM_THREADS=4
      - OPENBLAS_NUM_THREADS=4
      - EMBEDDING_MODEL_PROVIDER=ollama
      - EMBEDDING_MODEL=nomic-embed-text
    healthcheck:
      # Use the built‑in `ollama list` instead of curl for the
      # healthcheck. It will wait for the API to come online.
      test: ["CMD", "ollama", "list"]
      interval: 10s
      timeout: 5s
      retries: 30
      start_period: 10s
    volumes:
      - ollama:/root/.ollama

  ollama-init:
    image: ollama/ollama:latest
    depends_on:
      ollama:
        condition: service_healthy
    entrypoint: ["/bin/sh","-lc",
      "echo '>> Waiting for Ollama API...' && \
       until ollama list >/dev/null 2>&1; do sleep 1; done && \
       echo '>> Pull qwen2.5-coder:7b' && ollama pull qwen2.5-coder:7b && \
       echo '>> Pull nomic-embed-text' && ollama pull nomic-embed-text && \
       echo '>> Done.'"
    ]
    restart: "no"

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    restart: unless-stopped
    depends_on:
      - ollama
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - ENABLE_RAG_LOCAL=true
      # Reduce the number of parallel requests to Ollama
      - OLLAMA_NUM_PARALLEL=1
      # (optional) disable registration/signup
      # - WEBUI_AUTH=False
      - WHISPER_MODEL=large-v3
    ports:
      - "3000:8080"
    volumes:
      - openwebui:/app/backend/data

  # Python service providing a REST API to control Proxmox via proxmoxer.
  proxmox-controller:
    image: python:3.11-slim
    container_name: proxmox-controller
    restart: unless-stopped
    working_dir: /app
    # Bind mount the controller source code and requirements
    volumes:
      - ./controller:/app
    environment:
      - PROXMOX_HOST=${PROXMOX_HOST}
      - PROXMOX_USER=${PROXMOX_USER}
      - PROXMOX_TOKEN_NAME=${PROXMOX_TOKEN_NAME}
      - PROXMOX_TOKEN_VALUE=${PROXMOX_TOKEN_VALUE}
      - PROXMOX_VERIFY_SSL=${PROXMOX_VERIFY_SSL:-False}
    # Install requirements at runtime then launch the API server
    command: ["/bin/sh", "-c", "pip install -r requirements.txt && uvicorn app:app --host 0.0.0.0 --port 8000"]
    ports:
      - "8000:8000"
    depends_on:
      - ollama

volumes:
  ollama:
  openwebui: